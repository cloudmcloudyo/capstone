{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Capstone Project\n",
    "\n",
    "Notebook 1: Data Retrieving - Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script(name):\n",
    "    \n",
    "    # accessing the script page\n",
    "    url = 'https://www.imsdb.com/TV/'+name+'.html'\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200:\n",
    "        print(f'ACCESSING <{name.upper()}> SCRIPT PAGE...')\n",
    "    else:\n",
    "        print(f'UNABLE TO ACCESS {name.upper()} SCRIPT PAGE...')\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    \n",
    "    # locate the actual link for scripts\n",
    "    link = soup.find_all('a')[64:-7]\n",
    "    print(f'{len(link)} SCRIPTS FOUND!')\n",
    "\n",
    "    # find the right url to each episode webpage\n",
    "    ep_urls = []\n",
    "    for episode in list(range(len(link))):\n",
    "        branch = link[episode].attrs['href']\n",
    "        # format the scraped link to match with the actual link\n",
    "        branch_1 = branch[4:24].replace('T', 't')\n",
    "        branch_2 = branch[27:-12].replace(' ', '-')\n",
    "        branch_new = branch_1 + '-' + branch_2 + '.html'\n",
    "        branch_url = url[:-16]\n",
    "        ep_url = branch_url + branch_new\n",
    "        ep_urls.append(ep_url)\n",
    "    print(f'ON OUR WAY TO EPISODES!')\n",
    "    \n",
    "    # access each episodes page url using BeautifulSoup\n",
    "    \n",
    "    script_collection=[]\n",
    "    ep_no = 0\n",
    "    for sub in ep_urls:\n",
    "        ep_no += 1\n",
    "        ep_res = requests.get(sub)\n",
    "        if ep_res.status_code != 200:\n",
    "            print('ERROR ACCESSING EPISODE SCRIPTS...')\n",
    "        else:\n",
    "            ep_soup = BeautifulSoup(ep_res.content, 'lxml')\n",
    "            script = ep_soup.find('td', {'class': 'scrtext'})\n",
    "            script_new = script.find_all('pre')[0]\n",
    "            \n",
    "        # scrape script for each episode\n",
    "        # credit to Dan Wilhelm for helping me out on these codes. Thanks so much!\n",
    "        tags = []\n",
    "        actor = ''\n",
    "        lines = []\n",
    "        scripts = []\n",
    "        \n",
    "        for tag in script_new.contents:\n",
    "            if tag.name == 'b':\n",
    "                if tag.text.strip()!= '':\n",
    "                    if lines:\n",
    "                        scripts.append((actor, ' '.join(lines).replace('\\n', ' ').replace('  ', '')))\n",
    "                        lines = []\n",
    "                    actor = tag.text.strip()\n",
    "            else:\n",
    "                text = tag.strip()\n",
    "                if len(text)>0:\n",
    "                    lines.append(text)\n",
    "        scripts.append((actor, ' '.join(lines).replace('\\n', ' ').replace('  ', '')))\n",
    "        script_collection.append(scripts)\n",
    "        print(f'GENERATING SCRIPT OF EP.{ep_no} of {len(ep_urls)}')\n",
    "    return script_collection\n",
    "    print(f'ALL SCRIPTS RETRIEVED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESSING <SEINFELD> SCRIPT PAGE...\n",
      "176 SCRIPTS FOUND!\n",
      "ON OUR WAY TO EPISODES!\n",
      "GENERATING SCRIPT OF EP.1 of 176\n",
      "GENERATING SCRIPT OF EP.2 of 176\n",
      "GENERATING SCRIPT OF EP.3 of 176\n",
      "GENERATING SCRIPT OF EP.4 of 176\n"
     ]
    }
   ],
   "source": [
    "all_scripts = get_script('Seinfeld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scripts[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting scraped scripts to dataframe\n",
    "\n",
    "def convert_df(all_scripts, with_title_end=False):\n",
    "    df = pd.DataFrame(columns = ['character', 'line'])\n",
    "    for script in all_scripts:\n",
    "        \n",
    "        # exclude the title and the end of each script\n",
    "        if with_title_end == False:\n",
    "            df_script = pd.DataFrame(script[1:-2], columns = ['character', 'line'])\n",
    "            df = pd.concat([df, df_script], axis = 0)\n",
    "            \n",
    "        # include the title and the end of each script\n",
    "        else:\n",
    "            df_script = pd.DataFrame(script, columns = ['character', 'line'])\n",
    "            df = pd.concat([df, df_script], axis = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe with all lines\n",
    "\n",
    "without_title = convert_df(all_scripts)\n",
    "without_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe with all lines and titles & ends for each episode\n",
    "\n",
    "with_title = convert_df(all_scripts, with_title_end=True)\n",
    "with_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes\n",
    "\n",
    "without_title.to_csv('../data/seinfeld_scripts_no_title.csv', index=False)\n",
    "with_title.to_csv('../data/seinfeld_scripts_with_title.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
