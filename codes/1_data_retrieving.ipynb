{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Seinfeld Script Generator\n",
    "\n",
    "Notebook 1: Data Retrieving - Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Identification & Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I'm using for this project is the scripts of all 180 episodes of 90s hit sitcom <em>Seinfeld</em>.\n",
    "\n",
    "It is hosted by the Internet Movie Script Database ([IMSDb](https://www.imsdb.com/)), which is a renowned resource for movie and TV scripts. To make sure that data scraping is allowed, I checked the website's robots.txt (saved under `data` folder).\n",
    "\n",
    "![](../img/screenshot_imsdb_robots.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since IMSDb does not have an API for scraping, I build a function to automate the web scraping process. The function is composed of three parts: 1. locates the dedicated page for <em>Seinfeld</em> with the list of all episodes; 2. locates the dedicated pages for each episode; 3. scrapes scripts on each episode page.\n",
    "\n",
    "The challenges in building this function include: first, it took two redirctions from the original <em>Seinfeld</em> page to the script page, the urls are different and thus require additional string slicing; second, the scripts were formatted in a strange way that is not friendly to scraping, in that each character and their corresponding line are in seperate rows with blank tags that are hard to locate, as well as random spaces inserted between lines. A combination of string slicing and web scraping techniques are applied to make it work. As it's a long function, to examine the progress of my codes, I print out status updates every step of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_script(name):\n",
    "    \n",
    "    # accessing the script page\n",
    "    url = 'https://www.imsdb.com/TV/'+name+'.html'\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200:\n",
    "        print(f'ACCESSING <{name.upper()}> SCRIPT PAGE...')\n",
    "    else:\n",
    "        print(f'UNABLE TO ACCESS {name.upper()} SCRIPT PAGE...')\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    \n",
    "    # locate the actual link for scripts\n",
    "    link = soup.find_all('a')[64:-7]\n",
    "    print(f'{len(link)} SCRIPTS FOUND!')\n",
    "\n",
    "    # find the right url to each episode webpage\n",
    "    ep_urls = []\n",
    "    for episode in list(range(len(link))):\n",
    "        branch = link[episode].attrs['href']\n",
    "        # format the scraped link to match with the actual link\n",
    "        branch_1 = branch[4:24].replace('T', 't')\n",
    "        branch_2 = branch[27:-12].replace(' ', '-')\n",
    "        branch_new = branch_1 + '-' + branch_2 + '.html'\n",
    "        branch_url = url[:-16]\n",
    "        ep_url = branch_url + branch_new\n",
    "        ep_urls.append(ep_url)\n",
    "    print(f'ON OUR WAY TO EPISODES!')\n",
    "    \n",
    "    # access each episodes page url using BeautifulSoup\n",
    "    \n",
    "    script_collection=[]\n",
    "    ep_no = 0\n",
    "    for sub in ep_urls:\n",
    "        ep_no += 1\n",
    "        ep_res = requests.get(sub)\n",
    "        if ep_res.status_code != 200:\n",
    "            print('ERROR ACCESSING EPISODE SCRIPTS...')\n",
    "        else:\n",
    "            ep_soup = BeautifulSoup(ep_res.content, 'lxml')\n",
    "            script = ep_soup.find('td', {'class': 'scrtext'})\n",
    "            script_new = script.find_all('pre')[0]\n",
    "            \n",
    "        # scrape script for each episode\n",
    "        # credit to Dan Wilhelm for helping me out on these codes. Thanks so much!\n",
    "        tags = []\n",
    "        actor = ''\n",
    "        lines = []\n",
    "        scripts = []\n",
    "        \n",
    "        for tag in script_new.contents:\n",
    "            if tag.name == 'b':\n",
    "                if tag.text.strip()!= '':\n",
    "                    if lines:\n",
    "                        scripts.append((actor, ' '.join(lines).replace('\\n', ' ').replace('  ', '')))\n",
    "                        lines = []\n",
    "                    actor = tag.text.strip()\n",
    "            else:\n",
    "                text = tag.strip()\n",
    "                if len(text)>0:\n",
    "                    lines.append(text)\n",
    "        # create tuples that consist the character and the corresponding line for each script\n",
    "        scripts.append((actor, ' '.join(lines).replace('\\n', ' ').replace('  ', '')))\n",
    "        script_collection.append(scripts)\n",
    "        print(f'GENERATING SCRIPT OF EP.{ep_no} of {len(ep_urls)}')\n",
    "    return script_collection\n",
    "    print(f'ALL SCRIPTS RETRIEVED!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESSING <SEINFELD> SCRIPT PAGE...\n",
      "176 SCRIPTS FOUND!\n",
      "ON OUR WAY TO EPISODES!\n",
      "GENERATING SCRIPT OF EP.1 of 176\n",
      "GENERATING SCRIPT OF EP.2 of 176\n",
      "GENERATING SCRIPT OF EP.3 of 176\n",
      "GENERATING SCRIPT OF EP.4 of 176\n",
      "GENERATING SCRIPT OF EP.5 of 176\n",
      "GENERATING SCRIPT OF EP.6 of 176\n",
      "GENERATING SCRIPT OF EP.7 of 176\n",
      "GENERATING SCRIPT OF EP.8 of 176\n",
      "GENERATING SCRIPT OF EP.9 of 176\n",
      "GENERATING SCRIPT OF EP.10 of 176\n",
      "GENERATING SCRIPT OF EP.11 of 176\n",
      "GENERATING SCRIPT OF EP.12 of 176\n",
      "GENERATING SCRIPT OF EP.13 of 176\n",
      "GENERATING SCRIPT OF EP.14 of 176\n",
      "GENERATING SCRIPT OF EP.15 of 176\n",
      "GENERATING SCRIPT OF EP.16 of 176\n",
      "GENERATING SCRIPT OF EP.17 of 176\n",
      "GENERATING SCRIPT OF EP.18 of 176\n",
      "GENERATING SCRIPT OF EP.19 of 176\n",
      "GENERATING SCRIPT OF EP.20 of 176\n",
      "GENERATING SCRIPT OF EP.21 of 176\n",
      "GENERATING SCRIPT OF EP.22 of 176\n",
      "GENERATING SCRIPT OF EP.23 of 176\n",
      "GENERATING SCRIPT OF EP.24 of 176\n",
      "GENERATING SCRIPT OF EP.25 of 176\n",
      "GENERATING SCRIPT OF EP.26 of 176\n",
      "GENERATING SCRIPT OF EP.27 of 176\n",
      "GENERATING SCRIPT OF EP.28 of 176\n",
      "GENERATING SCRIPT OF EP.29 of 176\n",
      "GENERATING SCRIPT OF EP.30 of 176\n",
      "GENERATING SCRIPT OF EP.31 of 176\n",
      "GENERATING SCRIPT OF EP.32 of 176\n",
      "GENERATING SCRIPT OF EP.33 of 176\n",
      "GENERATING SCRIPT OF EP.34 of 176\n",
      "GENERATING SCRIPT OF EP.35 of 176\n",
      "GENERATING SCRIPT OF EP.36 of 176\n",
      "GENERATING SCRIPT OF EP.37 of 176\n",
      "GENERATING SCRIPT OF EP.38 of 176\n",
      "GENERATING SCRIPT OF EP.39 of 176\n",
      "GENERATING SCRIPT OF EP.40 of 176\n",
      "GENERATING SCRIPT OF EP.41 of 176\n",
      "GENERATING SCRIPT OF EP.42 of 176\n",
      "GENERATING SCRIPT OF EP.43 of 176\n",
      "GENERATING SCRIPT OF EP.44 of 176\n",
      "GENERATING SCRIPT OF EP.45 of 176\n",
      "GENERATING SCRIPT OF EP.46 of 176\n",
      "GENERATING SCRIPT OF EP.47 of 176\n",
      "GENERATING SCRIPT OF EP.48 of 176\n",
      "GENERATING SCRIPT OF EP.49 of 176\n",
      "GENERATING SCRIPT OF EP.50 of 176\n",
      "GENERATING SCRIPT OF EP.51 of 176\n",
      "GENERATING SCRIPT OF EP.52 of 176\n",
      "GENERATING SCRIPT OF EP.53 of 176\n",
      "GENERATING SCRIPT OF EP.54 of 176\n",
      "GENERATING SCRIPT OF EP.55 of 176\n",
      "GENERATING SCRIPT OF EP.56 of 176\n",
      "GENERATING SCRIPT OF EP.57 of 176\n",
      "GENERATING SCRIPT OF EP.58 of 176\n",
      "GENERATING SCRIPT OF EP.59 of 176\n",
      "GENERATING SCRIPT OF EP.60 of 176\n",
      "GENERATING SCRIPT OF EP.61 of 176\n",
      "GENERATING SCRIPT OF EP.62 of 176\n",
      "GENERATING SCRIPT OF EP.63 of 176\n",
      "GENERATING SCRIPT OF EP.64 of 176\n",
      "GENERATING SCRIPT OF EP.65 of 176\n",
      "GENERATING SCRIPT OF EP.66 of 176\n",
      "GENERATING SCRIPT OF EP.67 of 176\n",
      "GENERATING SCRIPT OF EP.68 of 176\n",
      "GENERATING SCRIPT OF EP.69 of 176\n",
      "GENERATING SCRIPT OF EP.70 of 176\n",
      "GENERATING SCRIPT OF EP.71 of 176\n",
      "GENERATING SCRIPT OF EP.72 of 176\n",
      "GENERATING SCRIPT OF EP.73 of 176\n",
      "GENERATING SCRIPT OF EP.74 of 176\n",
      "GENERATING SCRIPT OF EP.75 of 176\n",
      "GENERATING SCRIPT OF EP.76 of 176\n",
      "GENERATING SCRIPT OF EP.77 of 176\n",
      "GENERATING SCRIPT OF EP.78 of 176\n",
      "GENERATING SCRIPT OF EP.79 of 176\n",
      "GENERATING SCRIPT OF EP.80 of 176\n",
      "GENERATING SCRIPT OF EP.81 of 176\n",
      "GENERATING SCRIPT OF EP.82 of 176\n",
      "GENERATING SCRIPT OF EP.83 of 176\n",
      "GENERATING SCRIPT OF EP.84 of 176\n",
      "GENERATING SCRIPT OF EP.85 of 176\n",
      "GENERATING SCRIPT OF EP.86 of 176\n",
      "GENERATING SCRIPT OF EP.87 of 176\n",
      "GENERATING SCRIPT OF EP.88 of 176\n",
      "GENERATING SCRIPT OF EP.89 of 176\n",
      "GENERATING SCRIPT OF EP.90 of 176\n",
      "GENERATING SCRIPT OF EP.91 of 176\n",
      "GENERATING SCRIPT OF EP.92 of 176\n",
      "GENERATING SCRIPT OF EP.93 of 176\n",
      "GENERATING SCRIPT OF EP.94 of 176\n",
      "GENERATING SCRIPT OF EP.95 of 176\n",
      "GENERATING SCRIPT OF EP.96 of 176\n",
      "GENERATING SCRIPT OF EP.97 of 176\n",
      "GENERATING SCRIPT OF EP.98 of 176\n",
      "GENERATING SCRIPT OF EP.99 of 176\n",
      "GENERATING SCRIPT OF EP.100 of 176\n",
      "GENERATING SCRIPT OF EP.101 of 176\n",
      "GENERATING SCRIPT OF EP.102 of 176\n",
      "GENERATING SCRIPT OF EP.103 of 176\n",
      "GENERATING SCRIPT OF EP.104 of 176\n",
      "GENERATING SCRIPT OF EP.105 of 176\n",
      "GENERATING SCRIPT OF EP.106 of 176\n",
      "GENERATING SCRIPT OF EP.107 of 176\n",
      "GENERATING SCRIPT OF EP.108 of 176\n",
      "GENERATING SCRIPT OF EP.109 of 176\n",
      "GENERATING SCRIPT OF EP.110 of 176\n",
      "GENERATING SCRIPT OF EP.111 of 176\n",
      "GENERATING SCRIPT OF EP.112 of 176\n",
      "GENERATING SCRIPT OF EP.113 of 176\n",
      "GENERATING SCRIPT OF EP.114 of 176\n",
      "GENERATING SCRIPT OF EP.115 of 176\n",
      "GENERATING SCRIPT OF EP.116 of 176\n",
      "GENERATING SCRIPT OF EP.117 of 176\n",
      "GENERATING SCRIPT OF EP.118 of 176\n",
      "GENERATING SCRIPT OF EP.119 of 176\n",
      "GENERATING SCRIPT OF EP.120 of 176\n",
      "GENERATING SCRIPT OF EP.121 of 176\n",
      "GENERATING SCRIPT OF EP.122 of 176\n",
      "GENERATING SCRIPT OF EP.123 of 176\n",
      "GENERATING SCRIPT OF EP.124 of 176\n",
      "GENERATING SCRIPT OF EP.125 of 176\n",
      "GENERATING SCRIPT OF EP.126 of 176\n",
      "GENERATING SCRIPT OF EP.127 of 176\n",
      "GENERATING SCRIPT OF EP.128 of 176\n",
      "GENERATING SCRIPT OF EP.129 of 176\n",
      "GENERATING SCRIPT OF EP.130 of 176\n",
      "GENERATING SCRIPT OF EP.131 of 176\n",
      "GENERATING SCRIPT OF EP.132 of 176\n",
      "GENERATING SCRIPT OF EP.133 of 176\n",
      "GENERATING SCRIPT OF EP.134 of 176\n",
      "GENERATING SCRIPT OF EP.135 of 176\n",
      "GENERATING SCRIPT OF EP.136 of 176\n",
      "GENERATING SCRIPT OF EP.137 of 176\n",
      "GENERATING SCRIPT OF EP.138 of 176\n",
      "GENERATING SCRIPT OF EP.139 of 176\n",
      "GENERATING SCRIPT OF EP.140 of 176\n",
      "GENERATING SCRIPT OF EP.141 of 176\n",
      "GENERATING SCRIPT OF EP.142 of 176\n",
      "GENERATING SCRIPT OF EP.143 of 176\n",
      "GENERATING SCRIPT OF EP.144 of 176\n",
      "GENERATING SCRIPT OF EP.145 of 176\n",
      "GENERATING SCRIPT OF EP.146 of 176\n",
      "GENERATING SCRIPT OF EP.147 of 176\n",
      "GENERATING SCRIPT OF EP.148 of 176\n",
      "GENERATING SCRIPT OF EP.149 of 176\n",
      "GENERATING SCRIPT OF EP.150 of 176\n",
      "GENERATING SCRIPT OF EP.151 of 176\n",
      "GENERATING SCRIPT OF EP.152 of 176\n",
      "GENERATING SCRIPT OF EP.153 of 176\n",
      "GENERATING SCRIPT OF EP.154 of 176\n",
      "GENERATING SCRIPT OF EP.155 of 176\n",
      "GENERATING SCRIPT OF EP.156 of 176\n",
      "GENERATING SCRIPT OF EP.157 of 176\n",
      "GENERATING SCRIPT OF EP.158 of 176\n",
      "GENERATING SCRIPT OF EP.159 of 176\n",
      "GENERATING SCRIPT OF EP.160 of 176\n",
      "GENERATING SCRIPT OF EP.161 of 176\n",
      "GENERATING SCRIPT OF EP.162 of 176\n",
      "GENERATING SCRIPT OF EP.163 of 176\n",
      "GENERATING SCRIPT OF EP.164 of 176\n",
      "GENERATING SCRIPT OF EP.165 of 176\n",
      "GENERATING SCRIPT OF EP.166 of 176\n",
      "GENERATING SCRIPT OF EP.167 of 176\n",
      "GENERATING SCRIPT OF EP.168 of 176\n",
      "GENERATING SCRIPT OF EP.169 of 176\n",
      "GENERATING SCRIPT OF EP.170 of 176\n",
      "GENERATING SCRIPT OF EP.171 of 176\n",
      "GENERATING SCRIPT OF EP.172 of 176\n",
      "GENERATING SCRIPT OF EP.173 of 176\n",
      "GENERATING SCRIPT OF EP.174 of 176\n",
      "GENERATING SCRIPT OF EP.175 of 176\n",
      "GENERATING SCRIPT OF EP.176 of 176\n"
     ]
    }
   ],
   "source": [
    "all_scripts = get_script('Seinfeld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the official number of episodes in total for <em>Seinfeld</em> is 180 however only 176 were scraped. I will explore details at the EDA stage. \n",
    "\n",
    "For each script scraped, it is a list of numbers of tuples that contain the character who is speaking and the corresponding line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('JERRY',\n",
       " 'You know, why we\\'re here? To be out, this is out...and out is one of the single most enjoyable experiences of life. People...did you ever hear people talking about \"We should go out\"? This is what they\\'re talking about...this whole thing, we\\'re all out now, no one is home. Not one person here is home, we\\'re all out! There are people tryin\\' to find us, they don\\'t know where we are. (imitates one of these people \"tryin\\' to find us\"; pretends his hand is a phone) \"Did you ring?, I can\\'t find him.\" (imitates other person on phone) \"Where did he go?\" (the first person again) \"He didn\\'t tell me where he was going\". He must have gone out. You wanna go out: you get ready, you pick out the clothes, right? You take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...There you\\'re staring around, whatta you do? You go: \"We gotta be getting back\". Once you\\'re out, you wanna get back! You wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? Where ever you are in life, it\\'s my feeling, you\\'ve gotta go. (Pete\\'s luncheonette. Jerry and George are sitting at a table.)')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scripts[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all data scraped, my next step is to turn them into a dataframe. I built a function to achieve this. Note that the first and last row of every script contain the episode name, the writers and \"the end\", which are information that functions more as format rather than content indicators. I therefore decided to exclude them from the dataset that I would use to feed into the model. However, I added the episode name as a column for reference; and moreover, I made the function flexible by allowing the user to select if they want to include the title and ending or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GOOD NEWS, BAD NEWS', 'Written byLarry David & Jerry Seinfeld (Comedy club)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scripts[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting scraped scripts to dataframe\n",
    "\n",
    "def convert_df(all_scripts, with_title_end=False):\n",
    "    df = pd.DataFrame(columns = ['character', 'line', 'episode'])\n",
    "    for script in all_scripts:\n",
    "        \n",
    "        # exclude the title and the end of each script\n",
    "        if with_title_end == False:\n",
    "            df_script = pd.DataFrame(script[1:-2], columns = ['character', 'line'])\n",
    "            df_script['episode'] = script[0][0]\n",
    "            df = pd.concat([df, df_script], axis = 0)\n",
    "            \n",
    "        # include the title and the end of each script\n",
    "        else:\n",
    "            df_script = pd.DataFrame(script, columns = ['character', 'line'])\n",
    "            df_script['episode'] = script[0][0]\n",
    "            df = pd.concat([df, df_script], axis = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You know, why we're here? To be out, this is o...</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>Seems to me, that button is in the worst possi...</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through? (kind of irritated)</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I don't actual...</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character                                               line  \\\n",
       "0     JERRY  You know, why we're here? To be out, this is o...   \n",
       "1     JERRY  Seems to me, that button is in the worst possi...   \n",
       "2    GEORGE               Are you through? (kind of irritated)   \n",
       "3     JERRY             You do of course try on, when you buy?   \n",
       "4    GEORGE  Yes, it was purple, I liked it, I don't actual...   \n",
       "\n",
       "               episode  \n",
       "0  GOOD NEWS, BAD NEWS  \n",
       "1  GOOD NEWS, BAD NEWS  \n",
       "2  GOOD NEWS, BAD NEWS  \n",
       "3  GOOD NEWS, BAD NEWS  \n",
       "4  GOOD NEWS, BAD NEWS  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate dataframe with all lines\n",
    "\n",
    "without_title = convert_df(all_scripts)\n",
    "without_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "      <td>Written byLarry David &amp; Jerry Seinfeld (Comedy...</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You know, why we're here? To be out, this is o...</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>Seems to me, that button is in the worst possi...</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through? (kind of irritated)</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>GOOD NEWS, BAD NEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             character                                               line  \\\n",
       "0  GOOD NEWS, BAD NEWS  Written byLarry David & Jerry Seinfeld (Comedy...   \n",
       "1                JERRY  You know, why we're here? To be out, this is o...   \n",
       "2                JERRY  Seems to me, that button is in the worst possi...   \n",
       "3               GEORGE               Are you through? (kind of irritated)   \n",
       "4                JERRY             You do of course try on, when you buy?   \n",
       "\n",
       "               episode  \n",
       "0  GOOD NEWS, BAD NEWS  \n",
       "1  GOOD NEWS, BAD NEWS  \n",
       "2  GOOD NEWS, BAD NEWS  \n",
       "3  GOOD NEWS, BAD NEWS  \n",
       "4  GOOD NEWS, BAD NEWS  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate dataframe with all lines and titles & ends for each episode\n",
    "\n",
    "with_title = convert_df(all_scripts, with_title_end=True)\n",
    "with_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes\n",
    "\n",
    "without_title.to_csv('../data/scripts_no_title.csv', index=False)\n",
    "with_title.to_csv('../data/scripts_with_title.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
